{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119bbec4-5ac7-4f46-8c77-c91468d1c819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理文件夹中的 34 个音频文件...\n",
      "\n",
      "正在处理文件: 23.s「智醒．智慧醫療」第一堂：智慧醫療與日常生活的關係YF.wav\n",
      "加载 Whisper 模型...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 85\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# 运行主函数\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 85\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[7], line 81\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_segments\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 你可以修改这个输出文件夹\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# 处理文件夹中的所有音频文件\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m process_multiple_files(input_folder, output_folder)\n",
      "Cell \u001b[0;32mIn[7], line 70\u001b[0m, in \u001b[0;36mprocess_multiple_files\u001b[0;34m(input_folder, output_folder)\u001b[0m\n\u001b[1;32m     68\u001b[0m audio_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder, wav_file)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m正在处理文件: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwav_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m segment_audio_with_timestamps(audio_file_path, output_folder)\n",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m, in \u001b[0;36msegment_audio_with_timestamps\u001b[0;34m(audio_file_path, output_folder)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msegment_audio_with_timestamps\u001b[39m(audio_file_path, output_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_segments\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# 加载 Whisper 模型\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m加载 Whisper 模型...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlarge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# 转录音频并获取时间戳\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m转录音频文件: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.12/site-packages/whisper/__init__.py:150\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found; available models = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavailable_models()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m     )\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[1;32m    148\u001b[0m     io\u001b[38;5;241m.\u001b[39mBytesIO(checkpoint_file) \u001b[38;5;28;01mif\u001b[39;00m in_memory \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(checkpoint_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m--> 150\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(fp, map_location\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m checkpoint_file\n\u001b[1;32m    153\u001b[0m dims \u001b[38;5;241m=\u001b[39m ModelDimensions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheckpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdims\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.12/site-packages/torch/serialization.py:1360\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1359\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[1;32m   1361\u001b[0m             opened_zipfile,\n\u001b[1;32m   1362\u001b[0m             map_location,\n\u001b[1;32m   1363\u001b[0m             pickle_module,\n\u001b[1;32m   1364\u001b[0m             overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[1;32m   1365\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1366\u001b[0m         )\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1368\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.12/site-packages/torch/serialization.py:1848\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   1847\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1848\u001b[0m result \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m   1849\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1851\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.12/site-packages/torch/serialization.py:1812\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1811\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1812\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m load_tensor(\n\u001b[1;32m   1813\u001b[0m         dtype, nbytes, key, _maybe_decode_ascii(location)\n\u001b[1;32m   1814\u001b[0m     )\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.12/site-packages/torch/serialization.py:1784\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1779\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1784\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1785\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1786\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1787\u001b[0m )\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1790\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.12/site-packages/torch/serialization.py:1685\u001b[0m, in \u001b[0;36m_get_restore_location.<locals>.restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrestore_location\u001b[39m(storage, location):\n\u001b[0;32m-> 1685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_restore_location(storage, map_location)\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.12/site-packages/torch/serialization.py:601\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 601\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(storage, location)\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.12/site-packages/torch/serialization.py:540\u001b[0m, in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[1;32m    539\u001b[0m     device \u001b[38;5;241m=\u001b[39m _validate_device(location, backend_name)\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.12/site-packages/torch/storage.py:279\u001b[0m, in \u001b[0;36m_StorageBase.to\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, device: torch\u001b[38;5;241m.\u001b[39mdevice, non_blocking: _bool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    278\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[_StorageBase, TypedStorage]:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _to(\u001b[38;5;28mself\u001b[39m, device, non_blocking)\n",
      "File \u001b[0;32m~/miniconda3/envs/whisper/lib/python3.12/site-packages/torch/_utils.py:88\u001b[0m, in \u001b[0;36m_to\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_sparse\n\u001b[1;32m     87\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse storage is not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 88\u001b[0m     untyped_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize(), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     89\u001b[0m     untyped_storage\u001b[38;5;241m.\u001b[39mcopy_(\u001b[38;5;28mself\u001b[39m, non_blocking)\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import re\n",
    "import urllib.parse\n",
    "\n",
    "# 去除非法字符，确保文件名合法\n",
    "def sanitize_filename(text):\n",
    "    # 使用 URL 编码来确保中文字符不会导致文件名问题\n",
    "    return urllib.parse.quote(text)\n",
    "\n",
    "# 处理单个文件的音频分段\n",
    "def segment_audio_with_timestamps(audio_file_path, output_folder=\"output_segments\"):\n",
    "    # 加载 Whisper 模型\n",
    "    print(f\"加载 Whisper 模型...\")\n",
    "    model = whisper.load_model(\"large\")\n",
    "\n",
    "    # 转录音频并获取时间戳\n",
    "    print(f\"转录音频文件: {audio_file_path}...\")\n",
    "    result = model.transcribe(audio_file_path, word_timestamps=True)\n",
    "\n",
    "    # 加载音频文件\n",
    "    audio = AudioSegment.from_wav(audio_file_path)\n",
    "    print(f\"加载音频文件: {audio_file_path}\")\n",
    "\n",
    "    # 创建输出文件夹，如果不存在\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # 遍历每个字幕段并保存相应的音频片段\n",
    "    for idx, segment in enumerate(result['segments']):\n",
    "        start_time_ms = int(segment[\"start\"] * 1000)  # 转换为毫秒\n",
    "        end_time_ms = int(segment[\"end\"] * 1000)  # 转换为毫秒\n",
    "\n",
    "        # 切割音频段\n",
    "        audio_segment = audio[start_time_ms:end_time_ms]\n",
    "\n",
    "        # 使用字幕内容作为文件名，进行 URL 编码处理以支持繁体中文字符\n",
    "        subtitle_text = segment[\"text\"].strip()\n",
    "        if subtitle_text:  # 如果字幕非空\n",
    "            # 去除非法字符并使用 URL 编码以确保文件名合法\n",
    "            sanitized_name = sanitize_filename(subtitle_text) + \".wav\"\n",
    "            output_filename = os.path.join(output_folder, f\"segment_{idx + 1}_{sanitized_name}\")\n",
    "        else:\n",
    "            # 如果字幕为空，使用默认命名\n",
    "            output_filename = os.path.join(output_folder, f\"segment_{idx + 1}.wav\")\n",
    "\n",
    "        # 保存音频段到文件\n",
    "        audio_segment.export(output_filename, format=\"wav\")\n",
    "        print(f\"保存片段 {idx + 1} 到 {output_filename}\")\n",
    "\n",
    "    print(f\"音频分段完成，已保存 {len(result['segments'])} 个片段到 {output_folder}。\")\n",
    "\n",
    "# 处理多个音频文件的主函数\n",
    "def process_multiple_files(input_folder, output_folder=\"output_segments\"):\n",
    "    # 获取文件夹中的所有 .wav 文件\n",
    "    wav_files = [f for f in os.listdir(input_folder) if f.endswith(\".wav\")]\n",
    "    \n",
    "    # 如果没有找到 wav 文件\n",
    "    if not wav_files:\n",
    "        print(f\"在文件夹 {input_folder} 中没有找到任何 .wav 文件。\")\n",
    "        return\n",
    "\n",
    "    print(f\"开始处理文件夹中的 {len(wav_files)} 个音频文件...\")\n",
    "\n",
    "    # 遍历所有音频文件并调用分段处理函数\n",
    "    for wav_file in wav_files:\n",
    "        audio_file_path = os.path.join(input_folder, wav_file)\n",
    "        print(f\"\\n正在处理文件: {wav_file}\")\n",
    "        segment_audio_with_timestamps(audio_file_path, output_folder)\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    # 输入文件夹路径，包含所有的 .wav 文件\n",
    "    input_folder = \"/home/victor/AudioLDM-training-finetuning/data/Selected_audio\"  # 替换为你自己的文件夹路径\n",
    "\n",
    "    # 输出文件夹路径，保存切割后的音频片段\n",
    "    output_folder = \"output_segments\"  # 你可以修改这个输出文件夹\n",
    "\n",
    "    # 处理文件夹中的所有音频文件\n",
    "    process_multiple_files(input_folder, output_folder)\n",
    "\n",
    "# 运行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
